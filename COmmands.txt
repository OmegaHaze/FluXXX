docker build --no-cache -t vai:beta .



docker run -d --gpus all --runtime nvidia --name vai-beta --network fluXXX-net -p 7500:7500 -p 7501:7501 -p 11434:11434 -p 8188:8188 -e WEBUI_HOST=0.0.0.0 -e OLLAMA_CUDA=1 -e OLLAMA_API_BASE_URL=http://localhost:11434 -e OPENWEBUI_BACKEND_URL=http://localhost:7501 -e COMFYUI_API_BASE_URL=http://localhost:8188 -v open-webui:/workspace/open-webui/backend/data vai:beta 



copied Docker Run Command
(previously in the run command --hostname=821db4a1c519)
 
docker run --env=OLLAMA_CUDA=1 --env=OLLAMA_API_BASE_URL=http://localhost:11434 --env=OPENWEBUI_BACKEND_URL=http://localhost:7501 --env=COMFYUI_API_BASE_URL=http://localhost:8188 --env=WEBUI_HOST=0.0.0.0 --env=PATH=/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin --env=NVARCH=x86_64 --env=NVIDIA_REQUIRE_CUDA=cuda>=12.1 brand=tesla,driver>=470,driver<471 brand=unknown,driver>=470,driver<471 brand=nvidia,driver>=470,driver<471 brand=nvidiartx,driver>=470,driver<471 brand=geforce,driver>=470,driver<471 brand=geforcertx,driver>=470,driver<471 brand=quadro,driver>=470,driver<471 brand=quadrortx,driver>=470,driver<471 brand=titan,driver>=470,driver<471 brand=titanrtx,driver>=470,driver<471 brand=tesla,driver>=525,driver<526 brand=unknown,driver>=525,driver<526 brand=nvidia,driver>=525,driver<526 brand=nvidiartx,driver>=525,driver<526 brand=geforce,driver>=525,driver<526 brand=geforcertx,driver>=525,driver<526 brand=quadro,driver>=525,driver<526 brand=quadrortx,driver>=525,driver<526 brand=titan,driver>=525,driver<526 brand=titanrtx,driver>=525,driver<526 --env=NV_CUDA_CUDART_VERSION=12.1.105-1 --env=NV_CUDA_COMPAT_PACKAGE=cuda-compat-12-1 --env=CUDA_VERSION=12.1.1 --env=LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 --env=NVIDIA_VISIBLE_DEVICES=all --env=NVIDIA_DRIVER_CAPABILITIES=compute,utility --env=NV_CUDA_LIB_VERSION=12.1.1-1 --env=NV_NVTX_VERSION=12.1.105-1 --env=NV_LIBNPP_VERSION=12.1.0.40-1 --env=NV_LIBNPP_PACKAGE=libnpp-12-1=12.1.0.40-1 --env=NV_LIBCUSPARSE_VERSION=12.1.0.106-1 --env=NV_LIBCUBLAS_PACKAGE_NAME=libcublas-12-1 --env=NV_LIBCUBLAS_VERSION=12.1.3.1-1 --env=NV_LIBCUBLAS_PACKAGE=libcublas-12-1=12.1.3.1-1 --env=NV_LIBNCCL_PACKAGE_NAME=libnccl2 --env=NV_LIBNCCL_PACKAGE_VERSION=2.17.1-1 --env=NCCL_VERSION=2.17.1-1 --env=NV_LIBNCCL_PACKAGE=libnccl2=2.17.1-1+cuda12.1 --env=NVIDIA_PRODUCT_NAME=CUDA --env=NV_CUDNN_VERSION=8.9.0.131 --env=NV_CUDNN_PACKAGE_NAME=libcudnn8 --env=NV_CUDNN_PACKAGE=libcudnn8=8.9.0.131-1+cuda12.1 --env=DEBIAN_FRONTEND=noninteractive --env=PORT=7500 --env=CUDA_VISIBLE_DEVICES=0 --volume=open-webui:/workspace/open-webui/backend/data --network=fluXXX-net --workdir=/workspace -p 11434:11434 -p 7500:7500 -p 7501:7501 -p 8188:8188 --restart=no --label='com.nvidia.cudnn.version=8.9.0.131' --label='maintainer=NVIDIA CORPORATION <cudatools@nvidia.com>' --label='org.opencontainers.image.ref.name=ubuntu' --label='org.opencontainers.image.version=22.04' --runtime=runc -d voxveritas/fluxxx







On-start Script

Bash commands that are invoked whenever your instance starts, see FAQ/Docs for details.
touch /.noprovisioning && /workspace/entrypoint.sh




CLI Command
$
vastai create instance <OFFER_ID> --image voxveritas/fluxxx:latest --env '-p 1111:1111 -p 8080:8080 -p 8188:8188 -p 11434:11434 -p 7500:7500 -p 7501:7501 -e OPEN_BUTTON_PORT=1111 -e OPEN_BUTTON_TOKEN=1 -e JUPYTER_DIR=/ -e DATA_DIRECTORY=/workspace/ -e OLLAMA_CUDA=1 -e OLLAMA_API_BASE_URL=http://localhost:11434 -e OPENWEBUI_BACKEND_URL=http://localhost:7501 -e COMFYUI_API_BASE_URL=http://localhost:8188 -e WEBUI_HOST=0.0.0.0 -e PORTAL_CONFIG="localhost:1111:11111:/:Instance Portal|localhost:8188:18188:/:ComfyUI|localhost:7500:17500:/:Open Webui|localhost:11434:21434:/:Ollama API|localhost:8080:18080:/:Jupyter"' --onstart-cmd 'touch /.noprovisioning && /workspace/entrypoint.sh' --disk 48 --jupyter --ssh --direct



sudo apt-get update
sudo apt-get install nano

mkdir -p ~/.cloudflared

nano ~/.cloudflared/config.yaml











apt-get update


apt-get install -y nano


curl -LO https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64


chmod +x cloudflared-linux-amd64


mv cloudflared-linux-amd64 /usr/local/bin/cloudflared


cloudflared version


cloudflared tunnel login


cloudflared tunnel create fluxxx-omega


cloudflared tunnel route dns fluxxx-omega chat.askadolf.com

cloudflared tunnel route dns fluxxx-omega gen.askadolf.com



mkdir -p /root/.cloudflared
nano /root/.cloudflared/config.yml


tunnel: vai
credentials-file: /root/.cloudflared/1337918c-c3dc-4e4b-8272-8f9f1c602699.json

ingress:
  - hostname: chat.askadolf.com
    service: http://localhost:7500
  - hostname: gen.askadolf.com
    service: http://localhost:8188
  - service: http_status:404



cloudflared --config /root/.cloudflared/config.yml tunnel run fluxxx-omega




